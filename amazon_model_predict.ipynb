{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import six\n",
    "import sys\n",
    "\n",
    "import cifar_input\n",
    "import numpy as np\n",
    "import resnet_model\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import wget\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_name(img_url, f_name):\n",
    "    try:\n",
    "        file_name = wget.download(img_url, out= f_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_tensor(f_name):\n",
    "    image_size = 128\n",
    "    batch_size = 1\n",
    "    num_classes = 33\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(tf.gfile.Glob(f_name))\n",
    "    \n",
    "    image_reader = tf.WholeFileReader()\n",
    "\n",
    "    file_path, image_file = image_reader.read(filename_queue)\n",
    "    \n",
    "    \n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "        \n",
    "    longer = tf.reduce_max(tf.shape(image))\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, longer, longer)\n",
    "    image = tf.image.resize_images(image, [128, 128], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.image.resize_image_with_crop_or_pad(\n",
    "            image, image_size, image_size)\n",
    "    \n",
    "    temp_image = image\n",
    "    \n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    label = tf.Variable([1])\n",
    "    \n",
    "    indices = tf.reshape(tf.range(0, batch_size, 1), [batch_size, 1])\n",
    "    \n",
    "    image = tf.expand_dims(image, 0)\n",
    "    label = tf.expand_dims(label, 0)\n",
    "    \n",
    "    label = tf.sparse_to_dense(\n",
    "        tf.concat(values=[indices, label], axis=1),\n",
    "        [batch_size, num_classes], 1.0, 0.0)\n",
    "    \n",
    "    return image, label, temp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "cate_dict = joblib.load('./fasion_data/filtered_cate_mapping_dict_08_04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_idx_dict = {}\n",
    "\n",
    "for key, value in cate_dict.items():\n",
    "    cate_idx_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/jude/project/fdm/amazon_log_08_04/model.ckpt-77403\n",
      "[31]\n",
      "Clothing, Shoes & Jewelry||Women||Clothing||Swimsuits & Cover Ups\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1063, in _single_operation_run\n",
      "    target_list_as_strings, status, None)\n",
      "  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n",
      "    self.gen.next()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n",
      "    pywrap_tensorflow.TF_GetCode(status))\n",
      "CancelledError: Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    batch_size = 1\n",
    "    num_classes = 33\n",
    "\n",
    "    hps = resnet_model.HParams(batch_size=batch_size,\n",
    "                                   num_classes=num_classes,\n",
    "                                   min_lrn_rate=0.0001,\n",
    "                                   lrn_rate=0.1,\n",
    "                                   num_residual_units=5,\n",
    "                                   use_bottleneck=False,\n",
    "                                   weight_decay_rate=0.0002,\n",
    "                                   relu_leakiness=0.1,\n",
    "                                   optimizer='mom')\n",
    "    images = tf.placeholder(tf.float32, shape=(1, 128, 128, 3))\n",
    "    labels = tf.placeholder(tf.int32, shape=(1, 33))\n",
    "    model = resnet_model.ResNet(hps, images, labels, 'test')\n",
    "    model.build_graph()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    log_root = 'amazon_log_08_04/'\n",
    "\n",
    "    try:\n",
    "        ckpt_state = tf.train.get_checkpoint_state(log_root)\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        tf.logging.error('Cannot restore checkpoint: %s', e)\n",
    "\n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    img_url = 'http://shop1.phinf.naver.net/20170706_19/realrealiz_1499282886420r6Byg_JPEG/22590079963655237_-573053896.jpg?type=m450'\n",
    "    \n",
    "    image, label, temp_image = get_image_tensor(get_file_name(img_url, timestr))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver.restore(sess, os.getcwd() + '/' + ckpt_state.model_checkpoint_path)\n",
    "    \n",
    "    tf.train.start_queue_runners()\n",
    "    \n",
    "    img_eval = image.eval()\n",
    "    label_eval = label.eval()\n",
    "    \n",
    "    \n",
    "#     Image.fromarray(temp_image.eval(), 'RGB').save('bbb.jpeg')\n",
    "    feed_dict = {images: img_eval, labels: label_eval}\n",
    "    \n",
    "    predictions, labels, m_images = sess.run([model.predictions, model.labels, model._images], feed_dict)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    \n",
    "    print(predictions)\n",
    "    print(cate_idx_dict[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clothing, Shoes & Jewelry||Boys||Clothing||Sleepwear & Robes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_idx_dict[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
